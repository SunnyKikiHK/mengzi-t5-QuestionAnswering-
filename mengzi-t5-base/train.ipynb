{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e96d5b",
   "metadata": {},
   "source": [
    "# Call library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e51419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lamye\\miniconda3\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import read_json, get_data_stats, collote_fn\n",
    "from dataset import MengziT5Dataset\n",
    "from tqdm import tqdm \n",
    "\n",
    "\n",
    "checkpoint = \"Langboat/mengzi-t5-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b4671",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679b5ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Reading JSON file: 984it [00:00, 200592.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First valid data:  {'context': '年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。', 'answer': '年基准利率4.35%', 'question': '2017年银行贷款基准利率', 'id': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON file: 14520it [00:00, 139331.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First train data:  {'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。', 'answer': '第35集', 'question': '仙剑奇侠传3第几集上天界', 'id': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.json\"\n",
    "DATA_DEV_PATH = \"data/dev.json\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint) \n",
    "\n",
    "valid_data = read_json(DATA_DEV_PATH)\n",
    "print(\"First valid data: \", valid_data[0])\n",
    "train_data = read_json(DATA_TRAIN_PATH)\n",
    "print(\"First train data: \", train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fec6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_num': 984,\n",
       " 'context_num': 984,\n",
       " 'answer_num': 984,\n",
       " 'question_mean_length': 5.616869918699187,\n",
       " 'context_mean_length': 191.1971544715447,\n",
       " 'answer_mean_length': 3.9390243902439024,\n",
       " 'question_max_length': 17,\n",
       " 'context_max_length': 727,\n",
       " 'answer_max_length': 25}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_stats(valid_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09942fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_num': 14520,\n",
       " 'context_num': 14520,\n",
       " 'answer_num': 14520,\n",
       " 'question_mean_length': 5.561776859504132,\n",
       " 'context_mean_length': 181.33471074380165,\n",
       " 'answer_mean_length': 3.443595041322314,\n",
       " 'question_max_length': 27,\n",
       " 'context_max_length': 1176,\n",
       " 'answer_max_length': 94}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_stats(train_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9388d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data filtered away: 165\n",
      "Total data filtered away: 1906\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = MengziT5Dataset(valid_data)\n",
    "train_dataset = MengziT5Dataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa0fd0",
   "metadata": {},
   "source": [
    "# Retrieve Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9497a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "epoch_num = 3\n",
    "train_batch_size = 8\n",
    "valid_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc1aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_data['input_ids']:  tensor([[  143,    13,   544,  ...,     0,     0,     0],\n",
      "        [  143,    13, 13058,  ...,     0,     0,     0],\n",
      "        [  143,    13,   824,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  143,    13,  5003,  ...,     0,     0,     0],\n",
      "        [  143,    13,   217,  ...,     0,     0,     0],\n",
      "        [  143,    13,   105,  ...,     0,     0,     0]])\n",
      "batch_data['attention_mask']:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "batch_data['decoder_input_ids']:  tensor([[    0,  3620,   218,  ...,     0,     0,     0],\n",
      "        [    0,   586,  1063,  ...,     0,     0,     0],\n",
      "        [    0,  7030,  4739,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0,  1941,   252,  ...,     0,     0,     0],\n",
      "        [    0,  1957,  9458,  ...,     0,     0,     0],\n",
      "        [    0,   520, 16201,  ...,     0,     0,     0]])\n",
      "batch_data['labels']:  tensor([[ 3620,   218,  2582,  ...,  -100,  -100,  -100],\n",
      "        [  586,  1063,     1,  ...,  -100,  -100,  -100],\n",
      "        [ 7030,  4739,  5360,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [ 1941,   252,     1,  ...,  -100,  -100,  -100],\n",
      "        [ 1957,  9458,   310,  ...,  -100,  -100,  -100],\n",
      "        [  520, 16201,   105,  ...,  -100,  -100,  -100]])\n",
      "----------\n",
      "batch_data['input_ids']:  tensor([[  143,    13,  2536,  ...,     0,     0,     0],\n",
      "        [  143,    13,  2536,  ...,     0,     0,     0],\n",
      "        [  143,    13,    85,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  143,    13,   520,  ...,     0,     0,     0],\n",
      "        [  143,    13,  1257,  ...,     0,     0,     0],\n",
      "        [  143,    13, 16707,  ...,     0,     0,     0]])\n",
      "batch_data['attention_mask']:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "batch_data['decoder_input_ids']:  tensor([[    0,   173,  3588,  ...,     0,     0,     0],\n",
      "        [    0,   587,   173,  ...,     0,     0,     0],\n",
      "        [    0,  1616,    24,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0,   219,   880,  ...,     0,     0,     0],\n",
      "        [    0,  2056,   496,  ...,     0,     0,     0],\n",
      "        [    0,   603, 11812,  ...,     0,     0,     0]])\n",
      "batch_data['labels']:  tensor([[  173,  3588,  1073,  ...,  -100,  -100,  -100],\n",
      "        [  587,   173,  3588,  ...,  -100,  -100,  -100],\n",
      "        [ 1616,    24,    99,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [  219,   880,   131,  ...,  -100,  -100,  -100],\n",
      "        [ 2056,   496,   309,  ...,  -100,  -100,  -100],\n",
      "        [  603, 11812,     1,  ...,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size, collate_fn=lambda x: collote_fn(x, model, tokenizer))\n",
    "train_data = next(iter(train_dataloader))\n",
    "print(\"batch_data['input_ids']: \", train_data['input_ids'])\n",
    "print(\"batch_data['attention_mask']: \", train_data['attention_mask'])\n",
    "print(\"batch_data['decoder_input_ids']: \", train_data['decoder_input_ids'])\n",
    "print(\"batch_data['labels']: \", train_data['labels'])\n",
    "print(\"----------\")\n",
    "valid_dataloader = DataLoader(valid_dataset, shuffle=True, batch_size=valid_batch_size, collate_fn=lambda x: collote_fn(x, model, tokenizer))\n",
    "valid_data = next(iter(valid_dataloader))\n",
    "print(\"batch_data['input_ids']: \", valid_data['input_ids'])\n",
    "print(\"batch_data['attention_mask']: \", valid_data['attention_mask'])\n",
    "print(\"batch_data['decoder_input_ids']: \", valid_data['decoder_input_ids'])\n",
    "print(\"batch_data['labels']: \", valid_data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917848ee",
   "metadata": {},
   "source": [
    "# Train Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350c289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
