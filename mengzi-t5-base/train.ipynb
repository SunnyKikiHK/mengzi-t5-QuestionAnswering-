{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88e96d5b",
   "metadata": {},
   "source": [
    "# Call library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e51419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import torch\n",
    "import os\n",
    "import evaluate \n",
    "import wandb\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from utils import save_checkpoint, read_json, get_data_stats, collote_fn, MAX_TARGET_LENGTH\n",
    "from dataset import MengziT5Dataset\n",
    "from pathlib import Path\n",
    "from datetime import datetime \n",
    "from tqdm import tqdm \n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "checkpoint = \"Langboat/mengzi-t5-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b4671",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679b5ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON file: 984it [00:00, 11537.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First valid data:  {'context': '年基准利率4.35%。 从实际看,贷款的基本条件是: 一是中国大陆居民,年龄在60岁以下; 二是有稳定的住址和工作或经营地点; 三是有稳定的收入来源; 四是无不良信用记录,贷款用途不能作为炒股,赌博等行为; 五是具有完全民事行为能力。', 'answer': '年基准利率4.35%', 'question': '2017年银行贷款基准利率', 'id': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSON file: 14520it [00:00, 15388.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First train data:  {'context': '第35集雪见缓缓张开眼睛，景天又惊又喜之际，长卿和紫萱的仙船驶至，见众人无恙，也十分高兴。众人登船，用尽合力把自身的真气和水分输给她。雪见终于醒过来了，但却一脸木然，全无反应。众人向常胤求助，却发现人世界竟没有雪见的身世纪录。长卿询问清微的身世，清微语带双关说一切上了天界便有答案。长卿驾驶仙船，众人决定立马动身，往天界而去。众人来到一荒山，长卿指出，魔界和天界相连。由魔界进入通过神魔之井，便可登天。众人至魔界入口，仿若一黑色的蝙蝠洞，但始终无法进入。后来花楹发现只要有翅膀便能飞入。于是景天等人打下许多乌鸦，模仿重楼的翅膀，制作数对翅膀状巨物。刚佩戴在身，便被吸入洞口。众人摔落在地，抬头发现魔界守卫。景天和众魔套交情，自称和魔尊重楼相熟，众魔不理，打了起来。', 'answer': '第35集', 'question': '仙剑奇侠传3第几集上天界', 'id': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = \"data/train.json\"\n",
    "DATA_DEV_PATH = \"data/dev.json\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint) \n",
    "\n",
    "valid_data = read_json(DATA_DEV_PATH)\n",
    "print(\"First valid data: \", valid_data[0])\n",
    "train_data = read_json(DATA_TRAIN_PATH)\n",
    "print(\"First train data: \", train_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8fec6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_num': 984,\n",
       " 'context_num': 984,\n",
       " 'answer_num': 984,\n",
       " 'question_mean_length': 6.5426829268292686,\n",
       " 'context_mean_length': 192.15243902439025,\n",
       " 'answer_mean_length': 4.774390243902439,\n",
       " 'question_max_length': 18,\n",
       " 'context_max_length': 728,\n",
       " 'answer_max_length': 26}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_stats(valid_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09942fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_num': 14520,\n",
       " 'context_num': 14520,\n",
       " 'answer_num': 14520,\n",
       " 'question_mean_length': 6.488154269972452,\n",
       " 'context_mean_length': 182.3798209366391,\n",
       " 'answer_mean_length': 4.257782369146006,\n",
       " 'question_max_length': 28,\n",
       " 'context_max_length': 1180,\n",
       " 'answer_max_length': 95}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_stats(train_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9388d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data filtered away: 165\n",
      "Total data filtered away: 1906\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = MengziT5Dataset(valid_data)\n",
    "train_dataset = MengziT5Dataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaa0fd0",
   "metadata": {},
   "source": [
    "# Retrieve Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9497a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "valid_batch_size = 8\n",
    "test_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30dc1aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 282/282 [00:00<00:00, 500.08it/s, Materializing param=shared.weight]                                                       \n",
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train input_ids:  tensor([[  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0]])\n",
      "train attention_mask:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "train decoder_input_ids tensor([[    0,     7,   644,  ...,     0,     0,     0],\n",
      "        [    0,     7,   390,  ...,     0,     0,     0],\n",
      "        [    0, 12598,   419,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0,     7,  2687,  ...,     0,     0,     0],\n",
      "        [    0,     7,  8316,  ...,     0,     0,     0],\n",
      "        [    0,     7,  4265,  ...,     0,     0,     0]])\n",
      "train labels tensor([[    7,   644,  6891,  ...,  -100,  -100,  -100],\n",
      "        [    7,   390,  1291,  ...,  -100,  -100,  -100],\n",
      "        [12598,   419,   131,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [    7,  2687,  2129,  ...,  -100,  -100,  -100],\n",
      "        [    7,  8316,     1,  ...,  -100,  -100,  -100],\n",
      "        [    7,  4265,  1423,  ...,  -100,  -100,  -100]])\n",
      "----------\n",
      "valid input_ids:  tensor([[  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0],\n",
      "        [  7, 143,  13,  ...,   0,   0,   0]])\n",
      "valid attention_mask:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "valid decoder_input_ids:  tensor([[    0,     7,  4399,  ...,     0,     0,     0],\n",
      "        [    0,     7,   510,  ...,     0,     0,     0],\n",
      "        [    0,  8811,    50,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0,     7,   506,  ...,     0,     0,     0],\n",
      "        [    0,     7, 22232,  ...,     0,     0,     0],\n",
      "        [    0,     7,  2796,  ...,     0,     0,     0]])\n",
      "valid labels: tensor([[    7,  4399,  6416,  ...,  -100,  -100,  -100],\n",
      "        [    7,   510,  1377,  ...,  -100,  -100,  -100],\n",
      "        [ 8811,    50,   280,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [    7,   506,    50,  ...,  -100,  -100,  -100],\n",
      "        [    7, 22232,  4500,  ...,  -100,  -100,  -100],\n",
      "        [    7,  2796,  2191,  ...,  -100,  -100,  -100]])\n",
      "test input_ids:  tensor([[   7,  143,   13,  ...,    0,    0,    0],\n",
      "        [   7,  143, 4146,  ...,    0,    0,    0],\n",
      "        [   7,  143,   13,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   7,  143,   13,  ...,    0,    0,    0],\n",
      "        [   7,  143,   13,  ...,    0,    0,    0],\n",
      "        [   7,  143,   13,  ...,    0,    0,    0]])\n",
      "test attention_mask:  tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "test decoder_input_ids:  tensor([[    0,     7,  3498,  ...,     0,     0,     0],\n",
      "        [    0,     7,  7692,  ...,     0,     0,     0],\n",
      "        [    0,     7,   587,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    0,  3389,  7372,  ...,     0,     0,     0],\n",
      "        [    0,  3621, 15127,  ...,     0,     0,     0],\n",
      "        [    0,     7,  8601,  ...,     0,     0,     0]])\n",
      "test labels: tensor([[    7,  3498,  1685,  ...,  -100,  -100,  -100],\n",
      "        [    7,  7692,     1,  ...,  -100,  -100,  -100],\n",
      "        [    7,   587,   173,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [ 3389,  7372,   647,  ...,  -100,  -100,  -100],\n",
      "        [ 3621, 15127,     1,  ...,  -100,  -100,  -100],\n",
      "        [    7,  8601,  1169,  ...,  -100,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size, collate_fn=lambda x: collote_fn(x, model, tokenizer))\n",
    "train_data = next(iter(train_dataloader))\n",
    "print(\"train input_ids: \", train_data['input_ids'])\n",
    "print(\"train attention_mask: \", train_data['attention_mask'])\n",
    "print(\"train decoder_input_ids\", train_data['decoder_input_ids'])\n",
    "print(\"train labels\", train_data['labels'])\n",
    "print(\"----------\")\n",
    "\n",
    "valid_dataset, test_dataset = random_split(valid_dataset, [0.5, 0.5])\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=valid_batch_size, collate_fn=lambda x: collote_fn(x, model, tokenizer))\n",
    "valid_data = next(iter(valid_dataloader))\n",
    "print(\"valid input_ids: \", valid_data['input_ids'])\n",
    "print(\"valid attention_mask: \", valid_data['attention_mask'])\n",
    "print(\"valid decoder_input_ids: \", valid_data['decoder_input_ids'])\n",
    "print(\"valid labels:\", valid_data['labels'])\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=valid_batch_size, collate_fn=lambda x: collote_fn(x, model, tokenizer))\n",
    "test_data = next(iter(test_dataloader))\n",
    "print(\"test input_ids: \", test_data['input_ids'])\n",
    "print(\"test attention_mask: \", test_data['attention_mask'])\n",
    "print(\"test decoder_input_ids: \", test_data['decoder_input_ids'])\n",
    "print(\"test labels:\", test_data['labels'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917848ee",
   "metadata": {},
   "source": [
    "# Train Model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7350c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer, scheduler, epoch, use_wandb=False):\n",
    "    model.train()\n",
    "    # Reset loss counter at the start of the epoch\n",
    "    epoch_loss_sum = 0.0 \n",
    "    cumulative_batch = len(dataloader) * (epoch - 1)\n",
    "    \n",
    "    with tqdm(total=len(dataloader)) as pbar:\n",
    "        for batch_idx, batch_data in enumerate(dataloader, start=1):\n",
    "            batch_data = batch_data.to(device)\n",
    "            results = model(**batch_data)\n",
    "            loss = results.loss\n",
    "\n",
    "            # backward popagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            if use_wandb:\n",
    "                wandb.log(\n",
    "                    {\"train_loss\": loss.item()},\n",
    "                    step=cumulative_batch + batch_idx\n",
    "                )\n",
    "            epoch_loss_sum += loss.item()\n",
    "            current_avg_loss = epoch_loss_sum / batch_idx\n",
    "\n",
    "            pbar.set_description(f\"Epoch {epoch} | Avg Loss: {current_avg_loss:.4f}\")\n",
    "            pbar.update(1)\n",
    "    return current_avg_loss\n",
    "\n",
    "def valid_loop(dataloader, model, tokenizer, epoch, use_wandb=False):\n",
    "    model.eval()\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    cumulative_batch = (epoch-1) * len(dataloader)\n",
    "    with tqdm(total=len(dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(dataloader, start=1):\n",
    "                batch_data = batch_data.to(device)\n",
    "                results = model(**batch_data)\n",
    "                loss = results.loss\n",
    "\n",
    "                if use_wandb:\n",
    "                    wandb.log(\n",
    "                        {\"valid_loss\": loss.item()},\n",
    "                        step=cumulative_batch + batch_idx\n",
    "                    )\n",
    "\n",
    "                if batch_idx < 3:\n",
    "                    outputs = model.generate(\n",
    "                        batch_data[\"input_ids\"],\n",
    "                        attention_mask=batch_data[\"attention_mask\"],\n",
    "                        max_new_token=MAX_TARGET_LENGTH,\n",
    "                        num_beams=4\n",
    "                        )\n",
    "                    decoded_outputs = tokenizer.batch_decode(\n",
    "                        outputs,\n",
    "                        skip_special_tokens=True\n",
    "                        )\n",
    "                    labels = batch_data['labels']\n",
    "                    labels = torch.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "                    decoded_labels = tokenizer.batch_decode(\n",
    "                        labels,\n",
    "                        skip_special_tokens=True\n",
    "                    )\n",
    "\n",
    "                    preds = [' '.join(pred.strip()) for pred in decoded_outputs]\n",
    "                    labels = [' '.join(label.strip()) for label in decoded_labels]\n",
    "            bleu_result = bleu.compute(predictions=preds, references=labels)\n",
    "            result = {f\"bleu-{i}\" : value for i, value in enumerate(bleu_result[\"precisions\"], start=1)}\n",
    "            result['avg'] = np.mean(result.values())\n",
    "            if use_wandb:\n",
    "                wandb.log(\n",
    "                    {\"BLEU_avg\": result['avg']},\n",
    "                    step=epoch * len(dataloader)\n",
    "                )\n",
    "            print(f\"Test result: BLEU1={result['bleu-1']}, BLEU2={result['bleu-2']}, BLEU3={result['bleu-3']}, BLEU4={result['bleu-4']}\")\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5366ef4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "WANDB_API_KEY invalid: API key must have 40+ characters, has 20.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m use_wandb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_wandb:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmengzi-t5-qa\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# The name of your project on the website\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_t\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Name of this specific training run\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# Save hyperparameters for reference\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmengzi-t5-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m num_training_steps \u001b[38;5;241m=\u001b[39m epoch_num \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[1;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1595\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings, anonymous)\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wl:\n\u001b[1;32m   1593\u001b[0m     wl\u001b[38;5;241m.\u001b[39m_get_logger()\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m-> 1595\u001b[0m \u001b[43mget_sentry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/analytics/sentry.py:190\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    188\u001b[0m _, _, tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(exc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_traceback\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1516\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings, anonymous)\u001b[0m\n\u001b[1;32m   1512\u001b[0m wl \u001b[38;5;241m=\u001b[39m wandb_setup\u001b[38;5;241m.\u001b[39msingleton()\n\u001b[1;32m   1514\u001b[0m wi \u001b[38;5;241m=\u001b[39m _WandbInit(wl, init_telemetry)\n\u001b[0;32m-> 1516\u001b[0m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1517\u001b[0m run_settings, show_warnings \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39mmake_run_settings(init_settings)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(run_settings\u001b[38;5;241m.\u001b[39mreinit, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:196\u001b[0m, in \u001b[0;36m_WandbInit.maybe_login\u001b[0;34m(self, init_settings)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# Only pass an explicit key when the key was provided directly\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# to ensure correct messaging in _login().\u001b[39;00m\n\u001b[1;32m    194\u001b[0m explicit_key \u001b[38;5;241m=\u001b[39m init_settings\u001b[38;5;241m.\u001b[39mapi_key\n\u001b[0;32m--> 196\u001b[0m \u001b[43mwandb_login\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_silent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdate_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_key\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:190\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(key, relogin, host, force, timeout, verify, referrer, update_api_key, _silent)\u001b[0m\n\u001b[1;32m    182\u001b[0m     auth: wbauth\u001b[38;5;241m.\u001b[39mAuth \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m _use_explicit_key(\n\u001b[1;32m    183\u001b[0m         key,\n\u001b[1;32m    184\u001b[0m         host\u001b[38;5;241m=\u001b[39mhost_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m         silent\u001b[38;5;241m=\u001b[39m_silent,\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     auth \u001b[38;5;241m=\u001b[39m \u001b[43m_find_or_prompt_for_key\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelogin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelogin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreferrer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferrer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(auth, wbauth\u001b[38;5;241m.\u001b[39mAuthApiKey):\n\u001b[1;32m    200\u001b[0m     _verify_login(key\u001b[38;5;241m=\u001b[39mauth\u001b[38;5;241m.\u001b[39mapi_key, base_url\u001b[38;5;241m=\u001b[39mauth\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;241m.\u001b[39murl)\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/wandb_login.py:266\u001b[0m, in \u001b[0;36m_find_or_prompt_for_key\u001b[0;34m(settings, host, force, relogin, referrer, input_timeout)\u001b[0m\n\u001b[1;32m    263\u001b[0m auth: wbauth\u001b[38;5;241m.\u001b[39mAuth \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 266\u001b[0m     auth \u001b[38;5;241m=\u001b[39m \u001b[43mwbauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthenticate_session\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb.login()\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_offline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreferrer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreferrer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelogin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelogin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     timed_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/lib/wbauth/authenticate.py:126\u001b[0m, in \u001b[0;36mauthenticate_session\u001b[0;34m(host, source, no_offline, no_create, input_timeout, referrer, relogin)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m relogin \u001b[38;5;129;01mand\u001b[39;00m (auth \u001b[38;5;241m:=\u001b[39m session_credentials(host\u001b[38;5;241m=\u001b[39mhost)):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auth\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m relogin \u001b[38;5;129;01mand\u001b[39;00m (auth \u001b[38;5;241m:=\u001b[39m \u001b[43m_use_system_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auth\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/lib/wbauth/authenticate.py:187\u001b[0m, in \u001b[0;36m_use_system_auth\u001b[0;34m(host, source)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_use_system_auth\u001b[39m(\u001b[38;5;241m*\u001b[39m, host: HostUrl, source: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Auth \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load (or reload) session credentials from external sources.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    Loads credentials from environment variables or the .netrc file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m        The new credentials, if any.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     auth \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 187\u001b[0m         \u001b[43m_try_env_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m wbnetrc\u001b[38;5;241m.\u001b[39mread_netrc_auth_with_source(host\u001b[38;5;241m=\u001b[39mhost)\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _session_auth_lock:\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m auth:\n",
      "File \u001b[0;32m~/miniconda3/envs/my_ai_env/lib/python3.10/site-packages/wandb/sdk/lib/wbauth/authenticate.py:224\u001b[0m, in \u001b[0;36m_try_env_auth\u001b[0;34m(host)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m AuthWithSource(\n\u001b[1;32m    220\u001b[0m             auth\u001b[38;5;241m=\u001b[39mAuthApiKey(host\u001b[38;5;241m=\u001b[39mhost, api_key\u001b[38;5;241m=\u001b[39mapi_key),\n\u001b[1;32m    221\u001b[0m             source\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mAPI_KEY,\n\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m AuthenticationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 224\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mAPI_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m invalid: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m identity_token_file:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AuthWithSource(\n\u001b[1;32m    228\u001b[0m         auth\u001b[38;5;241m=\u001b[39mAuthIdentityTokenFile(host\u001b[38;5;241m=\u001b[39mhost, path\u001b[38;5;241m=\u001b[39midentity_token_file),\n\u001b[1;32m    229\u001b[0m         source\u001b[38;5;241m=\u001b[39menv\u001b[38;5;241m.\u001b[39mIDENTITY_TOKEN_FILE,\n\u001b[1;32m    230\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: WANDB_API_KEY invalid: API key must have 40+ characters, has 20."
     ]
    }
   ],
   "source": [
    "learning_rate = 2e-5\n",
    "epoch_num = 3\n",
    "best_model_name = \"best_t5.pt\"\n",
    "current_t = datetime.now().strftime('%d-%m-%y-%H_%M')\n",
    "foldername =  current_t + '_ckpt'\n",
    "checkpoint_path = Path(f\"./checkpoint/{foldername}\")\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "file_path = checkpoint_path / best_model_name\n",
    "recent_checkpoints = []\n",
    "use_wandb = True\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.init(\n",
    "        project=\"mengzi-t5-qa\",   # The name of project on the website\n",
    "        name=f\"{current_t}\",  # Name of this specific training run\n",
    "        config={        \n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"batch_size\": train_batch_size,\n",
    "            \"epochs\": epoch_num,\n",
    "            \"model\": \"mengzi-t5-base\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "num_training_steps = epoch_num * len(train_dataloader)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "best_bleu = 0\n",
    "for epoch in range(epoch_num):\n",
    "    avg_loss = train_loop(train_dataloader, model, optimizer, scheduler, epoch_num, use_wandb=use_wandb)\n",
    "    valid_bleu = valid_loop(valid_dataloader, model, use_wandb=use_wandb)\n",
    "    bleu_avg = valid_bleu['avg']\n",
    "    save_checkpoint(model, epoch, checkpoint_path, recent_checkpoints)\n",
    "    if bleu_avg > best_bleu:\n",
    "        best_bleu = bleu_avg \n",
    "        print(\"Saving new best weights ...\")\n",
    "        torch.save(model.static_dict() , file_path)\n",
    "        print(\"Finish saving.\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "\n",
    "print(\"Finish training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
