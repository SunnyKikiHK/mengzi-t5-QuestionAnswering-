{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cbeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import evaluate \n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, get_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from utils import read_json, collote_fn, MAX_TARGET_LENGTH\n",
    "from dataset import MengziT5Dataset\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm \n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "checkpoint = \"Langboat/mengzi-t5-base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fa85b",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80284dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DEV_PATH = \"data/dev.json\"\n",
    "\n",
    "valid_data = read_json(DATA_DEV_PATH)\n",
    "print(\"First valid data: \", valid_data[0])\n",
    "\n",
    "valid_dataset = MengziT5Dataset(valid_data)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=valid_batch_size, collate_fn=lambda x: collote_fn(x, model, tokenizer))\n",
    "test_data = next(iter(test_dataloader))\n",
    "print(\"test input_ids: \", test_data['input_ids'])\n",
    "print(\"test attention_mask: \", test_data['attention_mask'])\n",
    "print(\"test decoder_input_ids: \", test_data['decoder_input_ids'])\n",
    "print(\"test labels:\", test_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27243ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "best_model_name = \"best_t5.pt\"\n",
    "foldername =  '???????????_ckpt'\n",
    "checkpoint_path = Path(f\"./checkpoint/{foldername}\")\n",
    "file_path = checkpoint_path / best_model_name\n",
    "\n",
    "checkpoint = \"Langboat/mengzi-t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "model.load_state_dict(torch.load(file_path, weight_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea22b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, tokenizer):\n",
    "    model.eval()\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    with tqdm(total=len(dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(dataloader, start=1):\n",
    "                batch_data = batch_data.to(device)\n",
    "                outputs = model.generate(\n",
    "                    batch_data[\"input_ids\"],\n",
    "                    attention_mask=batch_data[\"attention_mask\"],\n",
    "                    max_new_token=MAX_TARGET_LENGTH,\n",
    "                    num_beams=4\n",
    "                    )\n",
    "                decoded_outputs = tokenizer.batch_decode(\n",
    "                    outputs,\n",
    "                    skip_special_tokens=True\n",
    "                    )\n",
    "                labels = batch_data['labels']\n",
    "                labels = torch.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "                decoded_labels = tokenizer.batch_decode(\n",
    "                    labels,\n",
    "                    skip_special_tokens=True\n",
    "                )\n",
    "\n",
    "                preds = [' '.join(pred.strip()) for pred in decoded_outputs]\n",
    "                labels = [' '.join(label.strip()) for label in decoded_labels]\n",
    "            bleu_result = bleu.compute(predictions=preds, references=labels)\n",
    "            result = {f\"bleu-{i}\" : value for i, value in enumerate(bleu_result[\"precisions\"], start=1)}\n",
    "            result['avg'] = np.mean(result.values())\n",
    "            print(f\"Test result: BLEU1={result[\"bleu-1\"]}, BLEU2={result[\"bleu-2\"]}, BLEU3={result[\"bleu-3\"]}, BLEU4={result[\"bleu-4\"]}\")\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loop(test_dataloader, model, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
